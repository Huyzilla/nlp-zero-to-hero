{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ee7a5c30",
      "metadata": {
        "papermill": {
          "duration": 0.01042,
          "end_time": "2023-02-20T20:26:22.817549",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.807129",
          "status": "completed"
        },
        "tags": [],
        "id": "ee7a5c30"
      },
      "source": [
        "<center>\n",
        "<img src='https://github.com/JUSTSUJAY/NLP_One_Shot/blob/main/assets/1/lang-pic.jpg?raw=1' width=600>\n",
        "</center>\n",
        "    \n",
        "# 1. Introduction\n",
        "\n",
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">1.1 NLP series</p>\n",
        "\n",
        "This is the **third in a series of notebooks** covering the **fundamentals of Natural Language Processing (NLP)**. I find that the best way to learn is by teaching others, hence why I am sharing my journey learning this field from scratch. I hope these notebooks can be helpful to you too.\n",
        "\n",
        "NLP series:\n",
        "\n",
        "1. [Tokenization](./01_Tokenization.ipynb)\n",
        "2. [Preprocessing](./02_Pre_Processing.ipynb)\n",
        "3. Bag of Words and Similarity\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/JUSTSUJAY/NLP_One_Shot/blob/main/Notebooks/03_BOW_Similarity.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "[![Kaggle](https://kaggle.com/static/images/open-in-kaggle.svg)](https://kaggle.com/kernels/welcome?src=https://github.com/JUSTSUJAY/NLP_One_Shot/blob/main/Notebooks/03_BOW_Similarity.ipynb)\n",
        "\n",
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">1.2 Outline</p>\n",
        "\n",
        "We have now seen how to tokenize and pre-process text. But to be able to use machine learning, we need to **convert this text into numbers**. In this notebook, we'll see one way to do this via a **basic bag-of-words** and discuss some of its variants.\n",
        "\n",
        "We'll then learn how to measure the **similarity between two documents** through one of the most popular approaches, namely **cosine similarity**."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "533b1345",
      "metadata": {
        "papermill": {
          "duration": 0.009552,
          "end_time": "2023-02-20T20:26:22.836571",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.827019",
          "status": "completed"
        },
        "tags": [],
        "id": "533b1345"
      },
      "source": [
        "# 2. Bag-of-Words\n",
        "\n",
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">2.1 Ý tưởng</p>\n",
        "\n",
        "Sau khi thực hiện **tách từ (tokenization)** và **tiền xử lý**, ta còn lại các chuỗi văn bản có **độ dài thay đổi**. Tuy nhiên, các thuật toán học máy lại yêu cầu **vector số có độ dài cố định**.  \n",
        "\n",
        "Cách tiếp cận **đơn giản nhất** để giải quyết vấn đề này là dùng **bag-of-words**, vốn chỉ đơn giản là **đếm số lần mỗi từ xuất hiện** trong một văn bản. Nó được gọi là **bag (túi)** vì **thứ tự từ bị bỏ qua** – ta chỉ quan tâm một từ có xuất hiện hay không.  \n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/JUSTSUJAY/NLP_One_Shot/blob/main/assets/3/basicbow.png?raw=1' width=600>\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Lý do ngôn ngữ học đằng sau phương pháp này là **các văn bản tương tự thường chia sẻ vốn từ vựng giống nhau**. Ví dụ, các bài báo về bóng đá sẽ thường chứa những từ như *score*, *pass*, *team*, trong khi bản tin thời tiết sẽ dùng bộ từ khác hoàn toàn như *rain*, *sun*, *umbrella*.  \n",
        "\n",
        "Ta có thể muốn **loại bỏ các stop words** (những từ phổ biến ít ý nghĩa như *the*, *of*, *how*) để dễ nhận diện các văn bản tương tự, vì các từ này gần như xuất hiện trong tất cả văn bản.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f316e827",
      "metadata": {
        "papermill": {
          "duration": 0.00896,
          "end_time": "2023-02-20T20:26:22.854538",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.845578",
          "status": "completed"
        },
        "tags": [],
        "id": "f316e827"
      },
      "source": [
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">2.2 Bag-of-Words Nhị Phân (Binary)</p>\n",
        "\n",
        "Ở đây, ta sẽ tập trung vào phiên bản **nhị phân** của bag-of-words. Phiên bản này chỉ cho biết **một từ có xuất hiện hay không**, bỏ qua cả **thứ tự** và **tần suất** xuất hiện.  \n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/JUSTSUJAY/NLP_One_Shot/blob/main/assets/3/binarybow.jpg?raw=1' width=600>\n",
        "</center>\n",
        "\n",
        "Mỗi **hàng** trong **ma trận bag-of-words nhị phân** tương ứng với một **văn bản** trong tập dữ liệu (corpus). Mỗi **cột** tương ứng với một **token** trong từ vựng. Lưu ý rằng thứ tự các token **không quan trọng**, nhưng phải được **cố định trước** khi xây dựng từ vựng.  \n",
        "\n",
        "Để **xây dựng** ma trận, ta đặt giá trị 1 ở ô (i, j) **nếu và chỉ nếu** token thứ j xuất hiện trong văn bản thứ i, ngược lại thì là 0.  \n",
        "\n",
        "Với một bag-of-words **tổng quát**, ô (i, j) sẽ thay bằng **tần suất** của token thứ j trong văn bản thứ i (nhưng ta sẽ thấy sau này có những cách tốt hơn để mã hóa tần suất).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b71e9590",
      "metadata": {
        "papermill": {
          "duration": 0.008651,
          "end_time": "2023-02-20T20:26:22.872352",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.863701",
          "status": "completed"
        },
        "tags": [],
        "id": "b71e9590"
      },
      "source": [
        "# 3. Độ Tương Tự (Similarity)\n",
        "\n",
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">3.1 Mô Hình Không Gian Vector (Vector Space Model)</p>\n",
        "\n",
        "Chúng ta đã chuyển từ việc coi văn bản như một chuỗi các từ sang coi chúng là **các điểm trong một không gian vector nhiều chiều**. Quan trọng là, số chiều của không gian này là **cố định**, nghĩa là mỗi vector đều có cùng độ dài.  \n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/JUSTSUJAY/NLP_One_Shot/blob/main/assets/3/unitcube.png?raw=1' width=400>\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Điều này rất hữu ích vì nó cho phép ta **đo khoảng cách** giữa các điểm (tài liệu). Những điểm (tài liệu) gần nhau sẽ tương ứng với các văn bản có **độ tương đồng cao** về mặt từ vựng.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3b4bdb58",
      "metadata": {
        "papermill": {
          "duration": 0.008661,
          "end_time": "2023-02-20T20:26:22.891809",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.883148",
          "status": "completed"
        },
        "tags": [],
        "id": "3b4bdb58"
      },
      "source": [
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">3.2 Độ Tương Tự Cosine (Cosine Similarity)</p>\n",
        "\n",
        "Có nhiều **thước đo (metrics)** khác nhau để đo mức độ “gần” nhau của hai điểm. Ví dụ, ta có thể dùng khoảng cách Euclid (Euclidean distance), khoảng cách Manhattan (Manhattan distance) hoặc thậm chí khoảng cách Hamming (Hamming distance). Tuy nhiên, nếu các văn bản trong cùng một tập có độ dài rất khác nhau, hoặc từ vựng quá lớn, thì các thước đo này trở nên kém tin cậy.  \n",
        "\n",
        "$$\n",
        "\\Large\n",
        "\\cos(\\theta) = \\frac{a \\cdot b}{\\|a\\| \\|b\\|}\n",
        "$$\n",
        "\n",
        "<br>\n",
        "\n",
        "Thay vào đó, trong lĩnh vực NLP, người ta thường dùng **Cosine Similarity**. Phương pháp này đo **cosin của góc** giữa hai vector (chính xác hơn là vector của chúng bắt đầu từ gốc tọa độ). **Giá trị càng gần 1**, góc giữa hai vector càng nhỏ và hai văn bản càng **giống nhau**.  \n",
        "\n",
        "<br>\n",
        "<center>\n",
        "<img src='https://github.com/JUSTSUJAY/NLP_One_Shot/blob/main/assets/3/cosine-similarity-vectors-original.jpg?raw=1' width=800>\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Lưu ý rằng **ngưỡng (threshold)** để quyết định hai văn bản có giống nhau hay không sẽ **phụ thuộc vào ứng dụng**, và có thể nằm ở bất kỳ đâu trong khoảng từ 0 đến 1. Kết quả cũng sẽ nhạy cảm với cách ta tiền xử lý văn bản. Việc **lemmatization** và loại bỏ **stop words** có thể giúp giảm kích thước từ vựng, từ đó dễ dàng hơn để nhận diện văn bản tương tự.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "01c445b2",
      "metadata": {
        "papermill": {
          "duration": 0.008747,
          "end_time": "2023-02-20T20:26:22.909611",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.900864",
          "status": "completed"
        },
        "tags": [],
        "id": "01c445b2"
      },
      "source": [
        "# 4. Mã hóa ngữ cảnh (Encoding context)\n",
        "\n",
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">4.1 Hạn chế của Bag-of-Words</p>\n",
        "\n",
        "Mặc dù bag-of-words là một công cụ tuyệt vời cho các ứng dụng NLP **đơn giản**, nhưng nó có một số hạn chế mà chúng ta cần lưu ý:\n",
        "\n",
        "* Không có cách nào xử lý các từ **ngoài từ vựng (Out-of-Vocabulary – OOV)**. Nếu một từ mới xuất hiện trong văn bản sau, nó sẽ bị bỏ qua.\n",
        "* Nó tạo ra **ma trận thưa (sparse matrices)**, có thể kém hiệu quả, mặc dù ta có thể khắc phục bằng cách dùng dạng biểu diễn từ điển (dictionary representation).\n",
        "* Không thể nắm bắt được sự tương đồng giữa các **từ đồng nghĩa**.\n",
        "* Thứ tự từ bị mất nên các từ **không có mối quan hệ** với nhau. Ví dụ, \"man eats bread\" (người đàn ông ăn bánh mì) rất khác với \"bread eats man\" (bánh mì ăn người), nhưng cả hai lại có cùng một biểu diễn.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f66b87e",
      "metadata": {
        "papermill": {
          "duration": 0.008656,
          "end_time": "2023-02-20T20:26:22.927304",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.918648",
          "status": "completed"
        },
        "tags": [],
        "id": "9f66b87e"
      },
      "source": [
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">4.2 n-grams</p>\n",
        "\n",
        "Một cách để khắc phục vấn đề **mất thông tin về thứ tự từ** là sử dụng **n-grams**. Đây là kỹ thuật gom các **cụm gồm n token** lại với nhau và coi chúng như một token duy nhất.  \n",
        "\n",
        "Một 2-gram (hay còn gọi là **bigram**) sẽ gồm 2 token trong mỗi cụm, một 3-gram (hay còn gọi là **trigram**) sẽ gồm 3 token, v.v.  \n",
        "\n",
        "<center>\n",
        "<img src='https://github.com/JUSTSUJAY/NLP_One_Shot/blob/main/assets/3/8ARA1.png?raw=1' width=600>\n",
        "</center>\n",
        "<br>\n",
        "\n",
        "Kỹ thuật này giúp ta nắm bắt được **một phần ngữ cảnh** mà việc dùng token đơn lẻ không làm được. **Từ vựng** lúc này sẽ trở thành **tập hợp các n-grams** được sinh ra. Tùy vào ứng dụng, ta có thể muốn dùng unigram kết hợp với bigram, hoặc chỉ dùng bigram. Ta cũng có thể lọc bỏ những bigram không hữu ích (ví dụ: chỉ giữ lại những bigram có tần suất cao hoặc bigram danh từ – danh từ).  \n",
        "\n",
        "Việc đo **độ tương tự** vẫn **giống như trước**. Tuy nhiên, việc sử dụng n-grams có thể **làm tăng kích thước từ vựng lên rất nhiều**, khiến cho việc tính toán trở nên chậm hơn. Do đó, luôn tồn tại sự đánh đổi giữa **mức độ thông tin ngữ cảnh** bổ sung và **thời gian tính toán** trong quá trình mô hình hóa.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "08eefb3d",
      "metadata": {
        "papermill": {
          "duration": 0.00869,
          "end_time": "2023-02-20T20:26:22.945178",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.936488",
          "status": "completed"
        },
        "tags": [],
        "id": "08eefb3d"
      },
      "source": [
        "# 5. Application\n",
        "\n",
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">5.1 Bag-of-Words using sklearn</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "490536c8",
      "metadata": {
        "papermill": {
          "duration": 0.008643,
          "end_time": "2023-02-20T20:26:22.962846",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.954203",
          "status": "completed"
        },
        "tags": [],
        "id": "490536c8"
      },
      "source": [
        "Import the **libraries**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "e03333dc",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:22.983236Z",
          "iopub.status.busy": "2023-02-20T20:26:22.982428Z",
          "iopub.status.idle": "2023-02-20T20:26:35.799727Z",
          "shell.execute_reply": "2023-02-20T20:26:35.798343Z"
        },
        "papermill": {
          "duration": 12.83109,
          "end_time": "2023-02-20T20:26:35.802954",
          "exception": false,
          "start_time": "2023-02-20T20:26:22.971864",
          "status": "completed"
        },
        "tags": [],
        "id": "e03333dc"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "020ffe04",
      "metadata": {
        "papermill": {
          "duration": 0.008675,
          "end_time": "2023-02-20T20:26:35.820878",
          "exception": false,
          "start_time": "2023-02-20T20:26:35.812203",
          "status": "completed"
        },
        "tags": [],
        "id": "020ffe04"
      },
      "source": [
        "Define the **corpus**. Here we use some of the top news stories from 2022."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "1d5171ff",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:35.840812Z",
          "iopub.status.busy": "2023-02-20T20:26:35.840144Z",
          "iopub.status.idle": "2023-02-20T20:26:35.845872Z",
          "shell.execute_reply": "2023-02-20T20:26:35.844509Z"
        },
        "papermill": {
          "duration": 0.018568,
          "end_time": "2023-02-20T20:26:35.848428",
          "exception": false,
          "start_time": "2023-02-20T20:26:35.829860",
          "status": "completed"
        },
        "tags": [],
        "id": "1d5171ff"
      },
      "outputs": [],
      "source": [
        "# A corpus containing a collection of sentences\n",
        "corpus = [\n",
        "    \"Inflation surges around the world.\",\n",
        "    \"The Omicron coronavirus variant spreads.\",\n",
        "    \"World population exceeds 8 billion.\",\n",
        "    \"AI predicts protein structures.\"\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06faa991",
      "metadata": {
        "papermill": {
          "duration": 0.008491,
          "end_time": "2023-02-20T20:26:35.866245",
          "exception": false,
          "start_time": "2023-02-20T20:26:35.857754",
          "status": "completed"
        },
        "tags": [],
        "id": "06faa991"
      },
      "source": [
        "We will use **sklearn's CountVectorizer** to create a bag-of-words matrix."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "34ad1ed5",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:35.886244Z",
          "iopub.status.busy": "2023-02-20T20:26:35.885823Z",
          "iopub.status.idle": "2023-02-20T20:26:35.891048Z",
          "shell.execute_reply": "2023-02-20T20:26:35.889655Z"
        },
        "papermill": {
          "duration": 0.018309,
          "end_time": "2023-02-20T20:26:35.893527",
          "exception": false,
          "start_time": "2023-02-20T20:26:35.875218",
          "status": "completed"
        },
        "tags": [],
        "id": "34ad1ed5"
      },
      "outputs": [],
      "source": [
        "# Initialize vectorizer\n",
        "vectorizer = CountVectorizer()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84d33b01",
      "metadata": {
        "papermill": {
          "duration": 0.009016,
          "end_time": "2023-02-20T20:26:35.911481",
          "exception": false,
          "start_time": "2023-02-20T20:26:35.902465",
          "status": "completed"
        },
        "tags": [],
        "id": "84d33b01"
      },
      "source": [
        "The `.fit_transform` method learns a **vocabulary** from the corpus and returns the **bag-of-words matrix**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a999f08e",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:35.931879Z",
          "iopub.status.busy": "2023-02-20T20:26:35.930755Z",
          "iopub.status.idle": "2023-02-20T20:26:35.940526Z",
          "shell.execute_reply": "2023-02-20T20:26:35.939390Z"
        },
        "papermill": {
          "duration": 0.022631,
          "end_time": "2023-02-20T20:26:35.943147",
          "exception": false,
          "start_time": "2023-02-20T20:26:35.920516",
          "status": "completed"
        },
        "tags": [],
        "id": "a999f08e"
      },
      "outputs": [],
      "source": [
        "# Fit vectorizer to corpus\n",
        "bow = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cfac95f",
      "metadata": {
        "papermill": {
          "duration": 0.00858,
          "end_time": "2023-02-20T20:26:35.960725",
          "exception": false,
          "start_time": "2023-02-20T20:26:35.952145",
          "status": "completed"
        },
        "tags": [],
        "id": "3cfac95f"
      },
      "source": [
        "Ta có thể xem **từ điển ánh xạ (vocabulary dictionary)** bằng phương thức `.vocabulary_`\n",
        "Ta cũng có thể dùng `.get_feature_names_out()` để chỉ xem danh sách các từ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "bef9eb24",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:35.980664Z",
          "iopub.status.busy": "2023-02-20T20:26:35.979635Z",
          "iopub.status.idle": "2023-02-20T20:26:35.990144Z",
          "shell.execute_reply": "2023-02-20T20:26:35.988945Z"
        },
        "papermill": {
          "duration": 0.022887,
          "end_time": "2023-02-20T20:26:35.992481",
          "exception": false,
          "start_time": "2023-02-20T20:26:35.969594",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bef9eb24",
        "outputId": "c2b89d6d-6383-4fa5-bbb2-aac26f6c2169"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'inflation': 5,\n",
              " 'surges': 12,\n",
              " 'around': 1,\n",
              " 'the': 13,\n",
              " 'world': 15,\n",
              " 'omicron': 6,\n",
              " 'coronavirus': 3,\n",
              " 'variant': 14,\n",
              " 'spreads': 10,\n",
              " 'population': 7,\n",
              " 'exceeds': 4,\n",
              " 'billion': 2,\n",
              " 'ai': 0,\n",
              " 'predicts': 8,\n",
              " 'protein': 9,\n",
              " 'structures': 11}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# View vocabulary\n",
        "vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "02d4c868",
      "metadata": {
        "papermill": {
          "duration": 0.008647,
          "end_time": "2023-02-20T20:26:36.010599",
          "exception": false,
          "start_time": "2023-02-20T20:26:36.001952",
          "status": "completed"
        },
        "tags": [],
        "id": "02d4c868"
      },
      "source": [
        "The vectorizer **output** is a **compressed sparse row matrix**, which is done to **improve memory efficiency**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "74d658c6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:36.031969Z",
          "iopub.status.busy": "2023-02-20T20:26:36.031524Z",
          "iopub.status.idle": "2023-02-20T20:26:36.038445Z",
          "shell.execute_reply": "2023-02-20T20:26:36.037332Z"
        },
        "papermill": {
          "duration": 0.020547,
          "end_time": "2023-02-20T20:26:36.040891",
          "exception": false,
          "start_time": "2023-02-20T20:26:36.020344",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74d658c6",
        "outputId": "6ffeb342-4b72-4fb9-c997-4cd43f8a24b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
              "\twith 18 stored elements and shape (4, 16)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7619b661",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:36.061208Z",
          "iopub.status.busy": "2023-02-20T20:26:36.060685Z",
          "iopub.status.idle": "2023-02-20T20:26:36.068220Z",
          "shell.execute_reply": "2023-02-20T20:26:36.067275Z"
        },
        "papermill": {
          "duration": 0.020542,
          "end_time": "2023-02-20T20:26:36.070763",
          "exception": false,
          "start_time": "2023-02-20T20:26:36.050221",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7619b661",
        "outputId": "af83a0d3-9bb0-4ee6-f2b9-6b943193229b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
            "\twith 18 stored elements and shape (4, 16)>\n",
            "  Coords\tValues\n",
            "  (0, 5)\t1\n",
            "  (0, 12)\t1\n",
            "  (0, 1)\t1\n",
            "  (0, 13)\t1\n",
            "  (0, 15)\t1\n",
            "  (1, 13)\t1\n",
            "  (1, 6)\t1\n",
            "  (1, 3)\t1\n",
            "  (1, 14)\t1\n",
            "  (1, 10)\t1\n",
            "  (2, 15)\t1\n",
            "  (2, 7)\t1\n",
            "  (2, 4)\t1\n",
            "  (2, 2)\t1\n",
            "  (3, 0)\t1\n",
            "  (3, 8)\t1\n",
            "  (3, 9)\t1\n",
            "  (3, 11)\t1\n"
          ]
        }
      ],
      "source": [
        "print(bow)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b295dec3",
      "metadata": {
        "papermill": {
          "duration": 0.009087,
          "end_time": "2023-02-20T20:26:36.089417",
          "exception": false,
          "start_time": "2023-02-20T20:26:36.080330",
          "status": "completed"
        },
        "tags": [],
        "id": "b295dec3"
      },
      "source": [
        "To convert the sparse matrix into a **dense matrix**, we call the `.toarray()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "3a511976",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:36.109856Z",
          "iopub.status.busy": "2023-02-20T20:26:36.109404Z",
          "iopub.status.idle": "2023-02-20T20:26:36.117204Z",
          "shell.execute_reply": "2023-02-20T20:26:36.115995Z"
        },
        "papermill": {
          "duration": 0.020823,
          "end_time": "2023-02-20T20:26:36.119671",
          "exception": false,
          "start_time": "2023-02-20T20:26:36.098848",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a511976",
        "outputId": "83799f31-335c-4ee6-83f3-e1270c743a4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1],\n",
              "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0],\n",
              "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Dense matrix representation\n",
        "bow.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d68bd14",
      "metadata": {
        "papermill": {
          "duration": 0.009037,
          "end_time": "2023-02-20T20:26:36.138627",
          "exception": false,
          "start_time": "2023-02-20T20:26:36.129590",
          "status": "completed"
        },
        "tags": [],
        "id": "6d68bd14"
      },
      "source": [
        "Notice how sklearn lower-cased and **tokenized the corpus for us**. Next we will do the same using our own **custom tokenizer**, which will give us **more control** over how the text is pre-processed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c9422a0a",
      "metadata": {
        "papermill": {
          "duration": 0.00903,
          "end_time": "2023-02-20T20:26:36.157123",
          "exception": false,
          "start_time": "2023-02-20T20:26:36.148093",
          "status": "completed"
        },
        "tags": [],
        "id": "c9422a0a"
      },
      "source": [
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">5.2 Custom tokenizer using spacy</p>\n",
        "\n",
        "To do this, we need to define our custom tokenizer as a **function** that given a document, **returns a list of tokens**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "0344fd70",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:36.177808Z",
          "iopub.status.busy": "2023-02-20T20:26:36.177395Z",
          "iopub.status.idle": "2023-02-20T20:26:37.046385Z",
          "shell.execute_reply": "2023-02-20T20:26:37.045101Z"
        },
        "papermill": {
          "duration": 0.882901,
          "end_time": "2023-02-20T20:26:37.049558",
          "exception": false,
          "start_time": "2023-02-20T20:26:36.166657",
          "status": "completed"
        },
        "tags": [],
        "id": "0344fd70"
      },
      "outputs": [],
      "source": [
        "# Load english language model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "# Define custom tokenizer (remove stop words and punctuation and apply lemmatization)\n",
        "def custom_tokenizer(doc):\n",
        "    return [t.lemma_ for t in nlp(doc) if (not t.is_punct) and (not t.is_stop)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "de078322",
      "metadata": {
        "papermill": {
          "duration": 0.009094,
          "end_time": "2023-02-20T20:26:37.068537",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.059443",
          "status": "completed"
        },
        "tags": [],
        "id": "de078322"
      },
      "source": [
        "The tokenizer is then passed as a **callback function** inside the count vectorizer. We also set binary equal to true to produce a **binary** bag-of-words."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4bf12d49",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.089399Z",
          "iopub.status.busy": "2023-02-20T20:26:37.088945Z",
          "iopub.status.idle": "2023-02-20T20:26:37.143032Z",
          "shell.execute_reply": "2023-02-20T20:26:37.141496Z"
        },
        "papermill": {
          "duration": 0.068061,
          "end_time": "2023-02-20T20:26:37.146147",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.078086",
          "status": "completed"
        },
        "tags": [],
        "id": "4bf12d49"
      },
      "outputs": [],
      "source": [
        "# Pass tokenizer as callback function to countvectorizer\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, binary=True)\n",
        "\n",
        "# Fit vectorizer to corpus\n",
        "bow = vectorizer.fit_transform(corpus)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68804981",
      "metadata": {
        "papermill": {
          "duration": 0.009161,
          "end_time": "2023-02-20T20:26:37.164922",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.155761",
          "status": "completed"
        },
        "tags": [],
        "id": "68804981"
      },
      "source": [
        "We can view the resulting **vocabulary** and matrix the same way as before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7cd0259b",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.185752Z",
          "iopub.status.busy": "2023-02-20T20:26:37.185295Z",
          "iopub.status.idle": "2023-02-20T20:26:37.193573Z",
          "shell.execute_reply": "2023-02-20T20:26:37.192393Z"
        },
        "papermill": {
          "duration": 0.021798,
          "end_time": "2023-02-20T20:26:37.196260",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.174462",
          "status": "completed"
        },
        "tags": [],
        "id": "7cd0259b",
        "outputId": "14db5c53-97f6-4524-ee2b-8441aaa63590"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'inflation': 5,\n",
              " 'surge': 12,\n",
              " 'world': 14,\n",
              " 'omicron': 6,\n",
              " 'coronavirus': 3,\n",
              " 'variant': 13,\n",
              " 'spread': 10,\n",
              " 'population': 7,\n",
              " 'exceed': 4,\n",
              " '8': 0,\n",
              " 'billion': 2,\n",
              " 'ai': 1,\n",
              " 'predict': 8,\n",
              " 'protein': 9,\n",
              " 'structure': 11}"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Vocabulary\n",
        "vectorizer.vocabulary_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd503d7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.217653Z",
          "iopub.status.busy": "2023-02-20T20:26:37.217245Z",
          "iopub.status.idle": "2023-02-20T20:26:37.225666Z",
          "shell.execute_reply": "2023-02-20T20:26:37.224301Z"
        },
        "papermill": {
          "duration": 0.02231,
          "end_time": "2023-02-20T20:26:37.228355",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.206045",
          "status": "completed"
        },
        "tags": [],
        "id": "ecd503d7",
        "outputId": "28617125-84d3-463e-bc92-3b795154f552"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1],\n",
              "       [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0],\n",
              "       [1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0]])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Dense matrix representation\n",
        "bow.toarray()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90c17cd4",
      "metadata": {
        "papermill": {
          "duration": 0.009533,
          "end_time": "2023-02-20T20:26:37.248180",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.238647",
          "status": "completed"
        },
        "tags": [],
        "id": "90c17cd4"
      },
      "source": [
        "The sparse matrix can be **sliced and indexed** like a normal array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb22e3b9",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.269425Z",
          "iopub.status.busy": "2023-02-20T20:26:37.268998Z",
          "iopub.status.idle": "2023-02-20T20:26:37.277379Z",
          "shell.execute_reply": "2023-02-20T20:26:37.276052Z"
        },
        "papermill": {
          "duration": 0.021918,
          "end_time": "2023-02-20T20:26:37.279871",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.257953",
          "status": "completed"
        },
        "tags": [],
        "id": "fb22e3b9",
        "outputId": "7b280416-960a-4357-9768-90055d07d263"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  (1, 3)\t1\n",
            "  (2, 0)\t1\n",
            "  (2, 2)\t1\n",
            "  (3, 1)\t1\n"
          ]
        }
      ],
      "source": [
        "# Sparse slice\n",
        "print(bow[:,0:4])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8451de04",
      "metadata": {
        "papermill": {
          "duration": 0.009506,
          "end_time": "2023-02-20T20:26:37.299823",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.290317",
          "status": "completed"
        },
        "tags": [],
        "id": "8451de04"
      },
      "source": [
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">5.3 Document Similarity</p>\n",
        "\n",
        "Here we will measure the **cosine similarity** between the documents in our corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b67402d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.323363Z",
          "iopub.status.busy": "2023-02-20T20:26:37.322930Z",
          "iopub.status.idle": "2023-02-20T20:26:37.329317Z",
          "shell.execute_reply": "2023-02-20T20:26:37.327933Z"
        },
        "papermill": {
          "duration": 0.021032,
          "end_time": "2023-02-20T20:26:37.331991",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.310959",
          "status": "completed"
        },
        "tags": [],
        "id": "b67402d3"
      },
      "outputs": [],
      "source": [
        "# Cosine similarity using numpy\n",
        "def cosine_sim(a,b):\n",
        "    return np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5c6703e2",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.354543Z",
          "iopub.status.busy": "2023-02-20T20:26:37.354134Z",
          "iopub.status.idle": "2023-02-20T20:26:37.361942Z",
          "shell.execute_reply": "2023-02-20T20:26:37.360577Z"
        },
        "papermill": {
          "duration": 0.021783,
          "end_time": "2023-02-20T20:26:37.364614",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.342831",
          "status": "completed"
        },
        "tags": [],
        "id": "5c6703e2",
        "outputId": "06a1f230-2c3d-4c42-c92e-f1a067eaed21"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The Omicron coronavirus variant spreads.\n",
            "AI predicts protein structures.\n",
            "Similarity score: 0.000\n"
          ]
        }
      ],
      "source": [
        "# Similarity between two documents\n",
        "print(corpus[1])\n",
        "print(corpus[3])\n",
        "print(f'Similarity score: {cosine_sim(bow[1].toarray().squeeze(),bow[3].toarray().squeeze()):.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fabe75b8",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.386779Z",
          "iopub.status.busy": "2023-02-20T20:26:37.386367Z",
          "iopub.status.idle": "2023-02-20T20:26:37.394173Z",
          "shell.execute_reply": "2023-02-20T20:26:37.392634Z"
        },
        "papermill": {
          "duration": 0.022003,
          "end_time": "2023-02-20T20:26:37.397017",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.375014",
          "status": "completed"
        },
        "tags": [],
        "id": "fabe75b8",
        "outputId": "1fcf057e-0466-463b-e03c-0fe9594593dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Inflation surges around the world.\n",
            "World population exceeds 8 billion.\n",
            "Similarity score: 0.258\n"
          ]
        }
      ],
      "source": [
        "# Similarity between two documents\n",
        "print(corpus[0])\n",
        "print(corpus[2])\n",
        "print(f'Similarity score: {cosine_sim(bow[0].toarray().squeeze(),bow[2].toarray().squeeze()):.3f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "78427adb",
      "metadata": {
        "papermill": {
          "duration": 0.009663,
          "end_time": "2023-02-20T20:26:37.416844",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.407181",
          "status": "completed"
        },
        "tags": [],
        "id": "78427adb"
      },
      "source": [
        "We can also use sklearn's `cosine_similarity`. This calculates all the **pairwise similarities** and returns the result in a matrix indexed by the documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "138b7b2f",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.439305Z",
          "iopub.status.busy": "2023-02-20T20:26:37.438897Z",
          "iopub.status.idle": "2023-02-20T20:26:37.449551Z",
          "shell.execute_reply": "2023-02-20T20:26:37.448323Z"
        },
        "papermill": {
          "duration": 0.025535,
          "end_time": "2023-02-20T20:26:37.452364",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.426829",
          "status": "completed"
        },
        "tags": [],
        "id": "138b7b2f",
        "outputId": "1bd19e91-4113-4693-e4c9-e732cb01a69c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.         0.         0.25819889 0.        ]\n",
            " [0.         1.         0.         0.        ]\n",
            " [0.25819889 0.         1.         0.        ]\n",
            " [0.         0.         0.         1.        ]]\n"
          ]
        }
      ],
      "source": [
        "# cosine_similarity takes either array-likes or sparse matrices\n",
        "print(cosine_similarity(bow))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2206adf0",
      "metadata": {
        "papermill": {
          "duration": 0.009759,
          "end_time": "2023-02-20T20:26:37.472221",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.462462",
          "status": "completed"
        },
        "tags": [],
        "id": "2206adf0"
      },
      "source": [
        "## <p style=\"font-family:JetBrains Mono; font-weight:normal; letter-spacing: 1px; color:#207d06; font-size:100%; text-align:left;padding: 0px; border-bottom: 3px solid #207d06;\">5.4 n-grams</p>\n",
        "\n",
        "Finally, we will build a bag-of-words matrix using **n-grams**. To do this, we can pass the `ngram_range` parameter in countvectorizer. It takes in a tuple, with the **first entry** indicating the **minimum** chunk size and the **second entry** indicating the **maximum** chunk size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f854df42",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.494203Z",
          "iopub.status.busy": "2023-02-20T20:26:37.493768Z",
          "iopub.status.idle": "2023-02-20T20:26:37.531349Z",
          "shell.execute_reply": "2023-02-20T20:26:37.530248Z"
        },
        "papermill": {
          "duration": 0.051787,
          "end_time": "2023-02-20T20:26:37.534216",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.482429",
          "status": "completed"
        },
        "tags": [],
        "id": "f854df42",
        "outputId": "d0de3bee-2afe-44f3-ac20-37749bf61452"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of vocabulary: 27\n",
            "{'inflation': 11, 'surge': 21, 'world': 25, 'inflation surge': 12, 'surge world': 22, 'Omicron': 4, 'coronavirus': 7, 'variant': 23, 'spread': 19, 'Omicron coronavirus': 5, 'coronavirus variant': 8, 'variant spread': 24, 'population': 13, 'exceed': 9, '8': 0, 'billion': 6, 'world population': 26, 'population exceed': 14, 'exceed 8': 10, '8 billion': 1, 'AI': 2, 'predict': 15, 'protein': 17, 'structure': 20, 'AI predict': 3, 'predict protein': 16, 'protein structure': 18}\n"
          ]
        }
      ],
      "source": [
        "# Unigrams and bigrams with ngram_range=(1,2)\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, lowercase=False, binary=True, ngram_range=(1,2))\n",
        "\n",
        "# Fit vectorizer to corpus\n",
        "unibigrams = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Print vocabulary size\n",
        "print(f'Size of vocabulary: {len(vectorizer.get_feature_names_out())}')\n",
        "\n",
        "# Print vocabulary\n",
        "print(vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d07fa58",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-02-20T20:26:37.557046Z",
          "iopub.status.busy": "2023-02-20T20:26:37.556623Z",
          "iopub.status.idle": "2023-02-20T20:26:37.593702Z",
          "shell.execute_reply": "2023-02-20T20:26:37.592525Z"
        },
        "papermill": {
          "duration": 0.052004,
          "end_time": "2023-02-20T20:26:37.596791",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.544787",
          "status": "completed"
        },
        "tags": [],
        "id": "7d07fa58",
        "outputId": "9dce65b7-0c17-42e3-aa73-18f5ac584f83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Size of vocabulary: 12\n",
            "{'inflation surge': 5, 'surge world': 9, 'Omicron coronavirus': 2, 'coronavirus variant': 3, 'variant spread': 10, 'world population': 11, 'population exceed': 6, 'exceed 8': 4, '8 billion': 0, 'AI predict': 1, 'predict protein': 7, 'protein structure': 8}\n"
          ]
        }
      ],
      "source": [
        "# Only bigrams with ngram_range=(2,2)\n",
        "vectorizer = CountVectorizer(tokenizer=custom_tokenizer, lowercase=False, binary=True, ngram_range=(2,2))\n",
        "\n",
        "# Fit vectorizer to corpus\n",
        "bigrams = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Print vocabulary size\n",
        "print(f'Size of vocabulary: {len(vectorizer.get_feature_names_out())}')\n",
        "\n",
        "# Print vocabulary\n",
        "print(vectorizer.vocabulary_)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74533f8e",
      "metadata": {
        "papermill": {
          "duration": 0.009863,
          "end_time": "2023-02-20T20:26:37.617101",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.607238",
          "status": "completed"
        },
        "tags": [],
        "id": "74533f8e"
      },
      "source": [
        "# 6. Conclusion\n",
        "\n",
        "In this notebook, we saw how to convert **sequences of text** to **vectors of numbers** by using a basic **bag-of-words**, a process sometimes called **vectorization**.  Whilst this can be used for simple applications, it has a number of **limitations** including **losing word order information**. This can be partially resolved by using **n-grams** but it comes at the cost of **increasing** the size of our vocabulary.\n",
        "\n",
        "We also investigated how to measure document similarity using the popular **cosine similarity** metric. We will build on these ideas in future notebooks."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beccc842",
      "metadata": {
        "papermill": {
          "duration": 0.009907,
          "end_time": "2023-02-20T20:26:37.637827",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.627920",
          "status": "completed"
        },
        "tags": [],
        "id": "beccc842"
      },
      "source": [
        "**References:**\n",
        "* [NLP demystified](https://www.nlpdemystified.org/)\n",
        "\n",
        "### Coming UP\n",
        "#### [4. TF-IDF and Document Search](./04_TFIDF_DocSearch.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88b9ae45",
      "metadata": {
        "papermill": {
          "duration": 0.010003,
          "end_time": "2023-02-20T20:26:37.658095",
          "exception": false,
          "start_time": "2023-02-20T20:26:37.648092",
          "status": "completed"
        },
        "tags": [],
        "id": "88b9ae45"
      },
      "source": [
        "Thanks for reading!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 28.842881,
      "end_time": "2023-02-20T20:26:40.760365",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-02-20T20:26:11.917484",
      "version": "2.3.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}